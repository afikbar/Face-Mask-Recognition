
= COVID-19 Face Mask Recognition
:doctype: article
:encoding: utf-8
:lang: en
:!toc:
:!numbered:
:nofooter:

[.text-right]
_Shahar Rotem +
Afik Bar_

== Data
The dataset contains `24,345` facial image, splitted to train and test sets.


.Train and Test Images samples, Respectively.
image::train_test_samples.png[,70%]


As we can see from this random samples, Images seems to cover a variety of ages (infants and seniors), and a multiple races. +
Furthermore, we can notice that the masks "type" are not fixed to certain color or shape. +
Both of the sets are balanced, as we can see from the following plots:

.Train and Test Images Mask Ratios, Respectively.
image::train_test_mask_ratio.png[,70%]


== Experiments

=== 7 Layers CNN
==== Preprocessing

To obtain better generalization, we've used several transformations:

- Random Cropping
- Random Horizontal Flipping
- Normalizing each color channel.

==== Model Architecture
Our neural network consists of 7 Convolutional layers with batch normalization & ReLU as activation function, 1 average pool, and 1 fully connected layers.

////
[uml,file="cnn_arch.png"]
--
queue Transform [
Preprocessing
....
3x224x224   
]

usecase Input [
Image
....
3x224x224
]

usecase Conv1 [
Conv1
....
16x224x224
]

usecase Conv2 [
Conv2
....
Max-Pool
....
16x112x112
]

usecase Conv3 [
Conv3
....
32x112x112
]

usecase Conv4 [
Conv4
....
Max-Pool
....
32x56x56
]

usecase Conv5 [
Conv5
....
32x56x56
]

usecase Conv6 [
Conv6
....
32x56x56
]

usecase Conv7 [
Conv7
....
Max-Pool
....
32x28x28
]


usecase AvgPool [
AvgPool
....
32x28x28
]

queue Flat [
Flattening
....
25,088 
]

usecase FC [
Fully
Connected
....
2
]

usecase Output [
Output
....
2
]

rectangle Softmax
storage Class

Input . Transform
Transform --> Conv1
Conv1 -> Conv2
Conv2 -> Conv3
Conv3 -> Conv4
Conv4 -> Conv5
Conv5 -> Conv6
Conv6 -> Conv7
Conv7 -> AvgPool
AvgPool -- Flat
Flat -> FC
FC -> Output
Output - Softmax
Softmax -> Class
--
////

.CNN Architecture
image::cnn_arch.png[]

===== Loss Function
We've used Cross Entropy loss function.


===== Optimizer
We've tried several different optimizers, with different configurations, and found out that Adam-Weighted performed slightly better, with default decay & learning rate.

==== Regularization
We found out that Dropout consistently preformed worse (Possibly due to Batch normalization). +
Our optimizer utilizes Weight decay, which limits the learned change in weights for each batch, we've used the default value of `0.01`.


==== Convergence

We were able to reach a F1-Score of `96.1` on the test-set.

.7 Layers CNN Convergence
image::cnn_graphs.png[,50%]


==== Conclusions
We found out that architecture changes had slight improvements over the data, and most of the improvements resulted from data augmentation.  




=== MobileNet


==== Preprocessing
To obtain better generalization, we've used several transformations:

- Random Cropping
- Random Horizontal Flipping
- Normalizing each color channel.


==== Model Architecture
We've used 
https://arxiv.org/pdf/1905.02244.pdf[MobileNet V3].

.Specification for MobileNetV3
image::mobilenet_arch_table.png[,50%]


===== Loss Function
We've used Cross Entropy loss function.

===== Optimizer
We've used Adam-Weighted Optimizer, along with Learning Rate Scheduler.
Our initial learning rate was `0.001`, and scheduler gamma is `0.1`.

==== Regularization
We found out that Dropout didn't affect results at all (Possibly due to Batch normalization). +
Our optimizer utilizes Weight decay, which limits the learned change in weights for each batch, we've used the default value of `0.01`.


==== Convergence
We were able to reach an accuracy of `97.95` on the test set.

.MobileNet Convergence
image::mobilenet_graphs.png[,50%]

==== Conclusions
We've tested multiple published models, however, MobileNet intrigued us the most, since it is intended to by used by low budget processing units (In smartphones), which we believe fit the task (:
Side note - 
PyTorch has an implementation of MobileNetV2, but we've found out that V3 performed just slightly better.


